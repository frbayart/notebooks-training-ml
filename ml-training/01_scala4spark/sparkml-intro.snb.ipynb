{
  "metadata" : {
    "id" : "98161851-0894-4a51-9bfc-a2d82af8a620",
    "name" : "sparkml-intro",
    "user_save_timestamp" : "1970-01-01T00:00:00.000Z",
    "auto_save_timestamp" : "1970-01-01T00:00:00.000Z",
    "language_info" : {
      "name" : "scala",
      "file_extension" : "scala",
      "codemirror_mode" : "text/x-scala"
    },
    "trusted" : true,
    "sparkNotebook" : null,
    "customLocalRepo" : null,
    "customRepos" : null,
    "customDeps" : null,
    "customImports" : null,
    "customArgs" : null,
    "customSparkConf" : null,
    "customVars" : null
  },
  "cells" : [ {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false,
      "id" : "C1D130204FBC469B824D3F52E741EECB"
    },
    "cell_type" : "code",
    "source" : [ "import org.apache.spark.ml.{Pipeline, PipelineModel}\n", "import org.apache.spark.ml.classification.LogisticRegression\n", "import org.apache.spark.ml.feature.{HashingTF, Tokenizer}\n", "import org.apache.spark.ml.linalg.Vector\n", "import org.apache.spark.sql.Row" ],
    "outputs" : [ ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false,
      "id" : "63F560BED5ED432889A6132101C9F45E"
    },
    "cell_type" : "code",
    "source" : [ "val spark = sparkSession" ],
    "outputs" : [ ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false,
      "id" : "266448021D9B4E5198952CF03EA7DB2F"
    },
    "cell_type" : "code",
    "source" : [ "val training = spark.createDataFrame(Seq(\n", "  (0L, \"a b c d e spark\", 1.0),\n", "  (1L, \"b d\", 0.0),\n", "  (2L, \"spark f g h\", 1.0),\n", "  (3L, \"hadoop mapreduce\", 0.0)\n", ")).toDF(\"id\", \"text\", \"label\")" ],
    "outputs" : [ ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false,
      "id" : "5B151F73E8F140EB97F8B4C5E79966DE"
    },
    "cell_type" : "code",
    "source" : [ "val tokenizer = new Tokenizer()\n", "  .setInputCol(\"text\")\n", "  .setOutputCol(\"words\")\n", "\n", "val hashingTF = new HashingTF()\n", "  .setNumFeatures(1000)\n", "  .setInputCol(tokenizer.getOutputCol)\n", "  .setOutputCol(\"features\")" ],
    "outputs" : [ ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false,
      "id" : "9C212B87254141D5898111507AEF07C7"
    },
    "cell_type" : "code",
    "source" : [ "val lr = new LogisticRegression()\n", "  .setMaxIter(10)\n", "  .setRegParam(0.001)" ],
    "outputs" : [ ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false,
      "id" : "112E7E90BAF4491DA6AF2976EBB7AD07"
    },
    "cell_type" : "code",
    "source" : [ "val pipeline = new Pipeline()\n", "  .setStages(Array(tokenizer, hashingTF, lr))" ],
    "outputs" : [ ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false,
      "id" : "B26F0BACA0BC49598DF9E8758FF99B73"
    },
    "cell_type" : "code",
    "source" : [ "val model = pipeline.fit(training)" ],
    "outputs" : [ ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false,
      "id" : "EACB0690F83F4F8680E3EE80794C8CD8"
    },
    "cell_type" : "code",
    "source" : [ "model.write.overwrite().save(\"/tmp/spark-logistic-regression-model\")" ],
    "outputs" : [ ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false,
      "id" : "B30378FBA46D460B8D2B3C5135B69E8B"
    },
    "cell_type" : "code",
    "source" : [ "pipeline.write.overwrite().save(\"/tmp/unfit-lr-model\")" ],
    "outputs" : [ ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false,
      "id" : "8730839C9D2D46C7887DB5FE3C0B9CAC"
    },
    "cell_type" : "code",
    "source" : [ "val sameModel = PipelineModel.load(\"/tmp/spark-logistic-regression-model\")" ],
    "outputs" : [ ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false,
      "id" : "5AD9C754E4304B988C1948014F4FC250"
    },
    "cell_type" : "code",
    "source" : [ "val test = spark.createDataFrame(Seq(\n", "  (4L, \"spark i j k\"),\n", "  (5L, \"l m n\"),\n", "  (6L, \"spark hadoop spark\"),\n", "  (7L, \"apache hadoop\")\n", ")).toDF(\"id\", \"text\")\n" ],
    "outputs" : [ ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false,
      "id" : "4E926D9F3173471C964B06A1314B965C"
    },
    "cell_type" : "code",
    "source" : [ "model.transform(test)\n", "  .select(\"id\", \"text\", \"probability\", \"prediction\")\n", "  .collect()\n", "  .foreach { case Row(id: Long, text: String, prob: Vector, prediction: Double) =>\n", "    println(s\"($id, $text) --> prob=$prob, prediction=$prediction\")\n", "  }" ],
    "outputs" : [ ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : true,
      "id" : "8B24D97C2DDC42FF8EC9598250D1EC92"
    },
    "cell_type" : "code",
    "source" : [ "" ],
    "outputs" : [ ]
  } ],
  "nbformat" : 4
}